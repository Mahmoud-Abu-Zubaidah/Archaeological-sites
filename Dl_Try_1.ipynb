{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required libraries"
      ],
      "metadata": {
        "id": "dMy87q6NSR5j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjEfU32SSMSW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.layers import Dense, Flatten,Dropout,ReLU,BatchNormalization,Softmax\n",
        "from tensorflow.keras.models import Model # Create a output sequence\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Augmantation\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB7 #Make infrance from the model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "# from keras.utils import plot_model  #Visualize Model\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmenter = ImageDataGenerator(rotation_range=30, horizontal_flip=True,width_shift_range=0.1,\n",
        "                               height_shift_range=0.1,shear_range=0.2,zoom_range=0.2,fill_mode='nearest')"
      ],
      "metadata": {
        "id": "wXI_yzhuZAiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = augmenter.flow_from_directory('/content/drive/MyDrive/project deep 1/data',(255,255),\"rgb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoMU5Sh-ZAcZ",
        "outputId": "5134f1c4-c9b8-4fcd-87b7-9fab0eb1807a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3960 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_network(base_model, classes):\n",
        "    \"\"\"\n",
        "    build a new network from a pre-trained model\n",
        "\n",
        "    parameters:\n",
        "        -base_model: pretraind model\n",
        "        -classes: number of classes to classify\n",
        "\n",
        "    \"\"\"\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(units=256)(x)\n",
        "    x = ReLU()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.5)(x)\n",
        "    x = Dense(units=classes)(x)\n",
        "    output = Softmax()(x)\n",
        "    return output\n",
        "\n",
        "\n",
        "def create_model(CLASSES,input_shape = (500,500,3)):\n",
        "  \"\"\"\n",
        "  Load the EfficientNetB7 models without the classifier part of the model.\n",
        "  Freeze all layers, and adding output layers and train it.\n",
        "\n",
        "  -------\n",
        "  param:\n",
        "    input_shape: image shape, It should have exactly 3 inputs channels.\n",
        "    num_classes: number of classes to classify\n",
        "  \"\"\"\n",
        "\n",
        "  # download the model and it's weights\n",
        "  base_model = EfficientNetB7(weights='imagenet',include_top=False,input_shape=input_shape)\n",
        "  # freeze layers\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  model = build_network(base_model, CLASSES)\n",
        "  model = Model(base_model.input, model)\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_model(6,(255,255,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgIS__WwEJIG",
        "outputId": "79692dd3-d602-4b20-cd7e-7efb718af3b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "258076736/258076736 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "xiPtEHAWEJFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(gen,3960 // 64,20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V_w-gsMFVm8",
        "outputId": "86f10001-7d6d-44e1-cdf8-371a171c32ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "61/61 [==============================] - 1658s 26s/step - loss: 1.3547 - accuracy: 0.5886\n",
            "Epoch 2/20\n",
            "61/61 [==============================] - 1542s 25s/step - loss: 0.8575 - accuracy: 0.7018\n",
            "Epoch 3/20\n",
            "61/61 [==============================] - 1528s 25s/step - loss: 0.7330 - accuracy: 0.7521\n",
            "Epoch 4/20\n",
            "61/61 [==============================] - 1529s 25s/step - loss: 0.6888 - accuracy: 0.7505\n",
            "Epoch 5/20\n",
            "61/61 [==============================] - 1536s 25s/step - loss: 0.6337 - accuracy: 0.7751\n",
            "Epoch 6/20\n",
            "61/61 [==============================] - 1573s 26s/step - loss: 0.5754 - accuracy: 0.7925\n",
            "Epoch 7/20\n",
            "61/61 [==============================] - 1543s 25s/step - loss: 0.5320 - accuracy: 0.8212\n",
            "Epoch 8/20\n",
            "61/61 [==============================] - 1511s 25s/step - loss: 0.4816 - accuracy: 0.8344\n",
            "Epoch 9/20\n",
            "61/61 [==============================] - 1551s 25s/step - loss: 0.4653 - accuracy: 0.8325\n",
            "Epoch 10/20\n",
            "61/61 [==============================] - 1515s 25s/step - loss: 0.4515 - accuracy: 0.8421\n",
            "Epoch 11/20\n",
            "61/61 [==============================] - 1556s 25s/step - loss: 0.4342 - accuracy: 0.8513\n",
            "Epoch 12/20\n",
            "61/61 [==============================] - 1551s 25s/step - loss: 0.3899 - accuracy: 0.8729\n",
            "Epoch 13/20\n",
            "61/61 [==============================] - 1558s 25s/step - loss: 0.4211 - accuracy: 0.8607\n",
            "Epoch 14/20\n",
            "61/61 [==============================] - 1585s 26s/step - loss: 0.3896 - accuracy: 0.8653\n",
            "Epoch 15/20\n",
            "61/61 [==============================] - 1565s 26s/step - loss: 0.3680 - accuracy: 0.8781\n",
            "Epoch 16/20\n",
            "26/61 [===========>..................] - ETA: 14:53 - loss: 0.3973 - accuracy: 0.8510"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/project deep 1/model #1.h5')"
      ],
      "metadata": {
        "id": "YmLi7ti1FVgk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}